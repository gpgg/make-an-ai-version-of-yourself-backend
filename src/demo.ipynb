{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda for inference.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"./wav2lip\")\n",
    "import os\n",
    "\n",
    "import openai\n",
    "import requests\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from dotenv import load_dotenv\n",
    "from flask import Flask, request, url_for, Response\n",
    "from flask_cors import CORS\n",
    "\n",
    "from wav2lip.video import generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "\n",
    "class Video:\n",
    "    def __init__(self,\n",
    "                 final_video_location='./static/result_video.mp4',\n",
    "                 idle_video_location='./static/input_video.mp4',\n",
    "                 input_audio_location='./static/input_audio.wav'):\n",
    "        self.final_video_location = final_video_location\n",
    "        self.idle_video_location = idle_video_location\n",
    "        self.input_audio_location = input_audio_location\n",
    "        self.url_prefix = \"http://localhost:8081/static/\"\n",
    "\n",
    "    def store_video(self):\n",
    "        status = generate(face=self.idle_video_location,\n",
    "                          input_audio=self.input_audio_location,\n",
    "                          checkpoint_path='./wav2lip/wav2lip_gan.pth',\n",
    "                          outfile=self.final_video_location,\n",
    "                          fps=25.,\n",
    "                          resize_factor=1,\n",
    "                          rotate=False,\n",
    "                          crop=[0, -1, 0, -1])\n",
    "        if status == 0:\n",
    "            print('video is generated.')\n",
    "\n",
    "    def get_final_video_url(self):\n",
    "        return self.url_prefix + \"result_video.mp4\"\n",
    "\n",
    "    def get_final_audio_url(self):\n",
    "        return self.url_prefix + \"input_audio.wav\"\n",
    "\n",
    "\n",
    "class Text:\n",
    "    def __init__(self,\n",
    "                 model_name=\"gpt-3.5-turbo\",\n",
    "                 system_setting=\"You are a helpful assistant \\\n",
    "                     that translates Chinese to English.\",\n",
    "                 user_template=\"Translate the following Chinese\\\n",
    "                     text to English: \"):\n",
    "        # Load your API key from an environment variable\n",
    "        # or secret management service\n",
    "        openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        self.chat_history = [\n",
    "            {\"role\": \"system\", \"content\": system_setting},\n",
    "        ]\n",
    "        self.model_name = model_name\n",
    "        self.system_setting = system_setting\n",
    "        self.user_template = user_template\n",
    "\n",
    "    def response(self, user_message):\n",
    "        self.chat_history.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": self.user_template + user_message\n",
    "        })\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model_name,\n",
    "            messages=self.chat_history\n",
    "        )\n",
    "\n",
    "        self.chat_history.append({\n",
    "            \"role\": response['choices'][0]['message']['role'],\n",
    "            \"content\": response['choices'][0]['message']['content']\n",
    "        })\n",
    "        return response['choices'][0]['message']['content']\n",
    "\n",
    "\n",
    "class Speech:\n",
    "    def __init__(self, text='Please say something'):\n",
    "        self.text = text\n",
    "\n",
    "    def store_audio(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class ElevenLabs(Speech):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.api_endpoint = \"https://api.elevenlabs.io/v1/text-to-speech/ErXwobaYiN019PkySvjV\"\n",
    "        self.api_key = os.getenv(\"ELEVENLABS_KEY\")\n",
    "\n",
    "    def store_audio(self, text, audio_location='./static/input_audio.mp3'):\n",
    "        headers = {\n",
    "                'accept': 'audio/mpeg',\n",
    "                'xi-api-key': self.api_key,\n",
    "                'Content-Type': 'application/json'\n",
    "        }\n",
    "        data = {\n",
    "            \"text\": text,\n",
    "            \"voice_settings\": {\n",
    "                \"stability\": 0,\n",
    "                \"similarity_boost\": 0\n",
    "            }\n",
    "        }\n",
    "        r = requests.post(self.api_endpoint, headers=headers, json=data)\n",
    "        r.raise_for_status()\n",
    "\n",
    "        assert r.headers[\"Content-Type\"] == \"audio/mpeg\"\n",
    "\n",
    "        with open(audio_location, \"wb\") as file:\n",
    "            file.write(r.content)\n",
    "        \n",
    "        # convert mp3 to wav\n",
    "        \n",
    "        sound = AudioSegment.from_mp3(audio_location)\n",
    "        sound.export(\"./static/input_audio.wav\", format=\"wav\")\n",
    "        print(\"audio is generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我要睡觉了\n"
     ]
    }
   ],
   "source": [
    "user_message = \"我要睡觉了\"\n",
    "print(user_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"I\\'m going to sleep now.\"'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user message -> bot message\n",
    "response_generator = Text()\n",
    "response = response_generator.response(user_message)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio is generated.\n"
     ]
    }
   ],
   "source": [
    "# bot message -> speech\n",
    "speech = ElevenLabs()\n",
    "speech.store_audio(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading video frames...\n",
      "Number of frames available for inference: 220\n",
      "(80, 134)\n",
      "Length of mel chunks: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:04<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load checkpoint from: ./wav2lip/wav2lip_gan.pth\n",
      "Model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video is generated.\n"
     ]
    }
   ],
   "source": [
    "# speech + idle video -> active video\n",
    "video_generator = Video()\n",
    "video_generator.store_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://localhost:8080\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [11/Mar/2023 13:00:36] \"OPTIONS /chat HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好\n",
      "generating response...\n",
      "generating speech...\n",
      "audio is generated.\n",
      "generating video...\n",
      "Reading video frames...\n",
      "Number of frames available for inference: 220\n",
      "(80, 278)\n",
      "Length of mel chunks: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:07<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load checkpoint from: ./wav2lip/wav2lip_gan.pth\n",
      "Model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.57s/it]\n",
      "127.0.0.1 - - [11/Mar/2023 13:00:49] \"POST /chat HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video is generated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [11/Mar/2023 13:01:42] \"OPTIONS /chat HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今天是星期六\n",
      "generating response...\n",
      "generating speech...\n",
      "audio is generated.\n",
      "generating video...\n",
      "Reading video frames...\n",
      "Number of frames available for inference: 220\n",
      "(80, 398)\n",
      "Length of mel chunks: 116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:03<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load checkpoint from: ./wav2lip/wav2lip_gan.pth\n",
      "Model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.99s/it]\n",
      "127.0.0.1 - - [11/Mar/2023 13:01:51] \"POST /chat HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video is generated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [11/Mar/2023 13:02:19] \"OPTIONS /chat HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "马上去吃午饭\n",
      "generating response...\n",
      "generating speech...\n",
      "audio is generated.\n",
      "generating video...\n",
      "Reading video frames...\n",
      "Number of frames available for inference: 220\n",
      "(80, 354)\n",
      "Length of mel chunks: 103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load checkpoint from: ./wav2lip/wav2lip_gan.pth\n",
      "Model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.91s/it]\n",
      "127.0.0.1 - - [11/Mar/2023 13:02:29] \"POST /chat HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video is generated.\n"
     ]
    }
   ],
   "source": [
    "# Server\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "\n",
    "@app.route(\"/chat\", methods=['POST'])\n",
    "def chat():\n",
    "    user_message = request.json.get('user_message')\n",
    "    print(user_message)\n",
    "\n",
    "    # user message -> bot message\n",
    "    print('generating response...')\n",
    "    response_generator = Text()\n",
    "    response = response_generator.response(user_message)\n",
    "\n",
    "    # bot message -> speech\n",
    "    print('generating speech...')\n",
    "    speech = ElevenLabs()\n",
    "    speech.store_audio(response)\n",
    "\n",
    "    # speech + idle video -> active video\n",
    "    print('generating video...')\n",
    "    video_generator = Video()\n",
    "    video_generator.store_video()\n",
    "\n",
    "    # url_for('static', filename='result_video.mp4')\n",
    "    # url_for('static', filename='input_audio.wav')\n",
    "    \n",
    "    return {\n",
    "        \"bot_message\": response,\n",
    "        \"audio_source\": video_generator.get_final_audio_url(),\n",
    "        \"video_source\": video_generator.get_final_video_url()\n",
    "    }, 200\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    from werkzeug.serving import run_simple\n",
    "    run_simple('localhost', 8080, app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
